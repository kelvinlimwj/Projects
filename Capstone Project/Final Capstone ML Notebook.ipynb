{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Sentiment Analysis with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = pd.read_csv('rotten_tomatoes_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          1   Manakamana doesn't answer any questions, yet ...\n",
       "1          1   Wilfully offensive and powered by a chest-thu...\n",
       "2          0   It would be difficult to imagine material mor...\n",
       "3          0   Despite the gusto its star brings to the role...\n",
       "4          0   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    240000\n",
       "0    240000\n",
       "Name: Freshness, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews['Freshness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Manakamana doesn't answer any questions, yet makes its point: Nepal, like the rest of our planet, is a picturesque but far from peaceable kingdom.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews['Review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x249414ae648>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_reviews.isnull().sum()\n",
    "\n",
    "sns.countplot(x='Freshness', data=movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_clean(text):\n",
    "    \n",
    "    # Remove all HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove all URL tags\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',text)\n",
    "    \n",
    "    # Keep text without punctuation\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "\n",
    "    # split text into a list of words\n",
    "    # token_text = re.split('\\W+',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews['cleaned_review'] = movie_reviews['Review'].apply(lambda x: string_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manakamana doesnt answer any questions yet makes its point nepal like the rest of our planet is a picturesque but far from peaceable kingdom'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews['cleaned_review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "      <td>manakamana doesnt answer any questions yet mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "      <td>wilfully offensive and powered by a chestthump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "      <td>it would be difficult to imagine material more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "      <td>despite the gusto its star brings to the role ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "      <td>if there was a good idea at the core of this f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review  \\\n",
       "0          1   Manakamana doesn't answer any questions, yet ...   \n",
       "1          1   Wilfully offensive and powered by a chest-thu...   \n",
       "2          0   It would be difficult to imagine material mor...   \n",
       "3          0   Despite the gusto its star brings to the role...   \n",
       "4          0   If there was a good idea at the core of this ...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  manakamana doesnt answer any questions yet mak...  \n",
       "1  wilfully offensive and powered by a chestthump...  \n",
       "2  it would be difficult to imagine material more...  \n",
       "3  despite the gusto its star brings to the role ...  \n",
       "4  if there was a good idea at the core of this f...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    \n",
    "    en_stopwords = list(nltk.corpus.stopwords.words('english'))\n",
    "    text = [word for word in text.split() if word not in en_stopwords]\n",
    "    \n",
    "    # initialize an empty string \n",
    "    word_string = \" \" \n",
    "    \n",
    "    # return string   \n",
    "    return (word_string.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews['stopped_review'] = movie_reviews['cleaned_review'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = movie_reviews[['Review','cleaned_review','stopped_review','Freshness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>stopped_review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "      <td>manakamana doesnt answer any questions yet mak...</td>\n",
       "      <td>manakamana doesnt answer questions yet makes p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "      <td>wilfully offensive and powered by a chestthump...</td>\n",
       "      <td>wilfully offensive powered chestthumping machi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "      <td>it would be difficult to imagine material more...</td>\n",
       "      <td>would difficult imagine material wrong spade l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "      <td>despite the gusto its star brings to the role ...</td>\n",
       "      <td>despite gusto star brings role hard ride shotg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "      <td>if there was a good idea at the core of this f...</td>\n",
       "      <td>good idea core film buried unsightly pile flat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0   Manakamana doesn't answer any questions, yet ...   \n",
       "1   Wilfully offensive and powered by a chest-thu...   \n",
       "2   It would be difficult to imagine material mor...   \n",
       "3   Despite the gusto its star brings to the role...   \n",
       "4   If there was a good idea at the core of this ...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  manakamana doesnt answer any questions yet mak...   \n",
       "1  wilfully offensive and powered by a chestthump...   \n",
       "2  it would be difficult to imagine material more...   \n",
       "3  despite the gusto its star brings to the role ...   \n",
       "4  if there was a good idea at the core of this f...   \n",
       "\n",
       "                                      stopped_review  Freshness  \n",
       "0  manakamana doesnt answer questions yet makes p...          1  \n",
       "1  wilfully offensive powered chestthumping machi...          1  \n",
       "2  would difficult imagine material wrong spade l...          0  \n",
       "3  despite gusto star brings role hard ride shotg...          0  \n",
       "4  good idea core film buried unsightly pile flat...          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemmer(text):\n",
    "    \n",
    "    text = [lemmatizer.lemmatize(i) for i in text.split()]\n",
    "    text = [p_stemmer.stem(i) for i in text]\n",
    "    \n",
    "    # initialize an empty string \n",
    "    word_string = \" \" \n",
    "    # return string   \n",
    "    return (word_string.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews['final_review'] = movie_reviews['stopped_review'].apply(lambda x: lemmatize_stemmer(x))\n",
    "movie_reviews = movie_reviews[['Review','cleaned_review','stopped_review','final_review','Freshness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>stopped_review</th>\n",
       "      <th>final_review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "      <td>manakamana doesnt answer any questions yet mak...</td>\n",
       "      <td>manakamana doesnt answer questions yet makes p...</td>\n",
       "      <td>manakamana doesnt answer question yet make poi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "      <td>wilfully offensive and powered by a chestthump...</td>\n",
       "      <td>wilfully offensive powered chestthumping machi...</td>\n",
       "      <td>wil offens power chestthump machismo good clea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "      <td>it would be difficult to imagine material more...</td>\n",
       "      <td>would difficult imagine material wrong spade l...</td>\n",
       "      <td>would difficult imagin materi wrong spade lost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "      <td>despite the gusto its star brings to the role ...</td>\n",
       "      <td>despite gusto star brings role hard ride shotg...</td>\n",
       "      <td>despit gusto star bring role hard ride shotgun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "      <td>if there was a good idea at the core of this f...</td>\n",
       "      <td>good idea core film buried unsightly pile flat...</td>\n",
       "      <td>good idea core film buri unsightli pile flatul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0   Manakamana doesn't answer any questions, yet ...   \n",
       "1   Wilfully offensive and powered by a chest-thu...   \n",
       "2   It would be difficult to imagine material mor...   \n",
       "3   Despite the gusto its star brings to the role...   \n",
       "4   If there was a good idea at the core of this ...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  manakamana doesnt answer any questions yet mak...   \n",
       "1  wilfully offensive and powered by a chestthump...   \n",
       "2  it would be difficult to imagine material more...   \n",
       "3  despite the gusto its star brings to the role ...   \n",
       "4  if there was a good idea at the core of this f...   \n",
       "\n",
       "                                      stopped_review  \\\n",
       "0  manakamana doesnt answer questions yet makes p...   \n",
       "1  wilfully offensive powered chestthumping machi...   \n",
       "2  would difficult imagine material wrong spade l...   \n",
       "3  despite gusto star brings role hard ride shotg...   \n",
       "4  good idea core film buried unsightly pile flat...   \n",
       "\n",
       "                                        final_review  Freshness  \n",
       "0  manakamana doesnt answer question yet make poi...          1  \n",
       "1  wil offens power chestthump machismo good clea...          1  \n",
       "2  would difficult imagin materi wrong spade lost...          0  \n",
       "3  despit gusto star bring role hard ride shotgun...          0  \n",
       "4  good idea core film buri unsightli pile flatul...          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews.to_csv('cleaned_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movie_reviews['stopped_review']\n",
    "#X_lemma = movie_reviews['final_review']\n",
    "y = movie_reviews['Freshness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_searcher(X, y, vectorizer, model):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=y)\n",
    "    \n",
    "    full_name_dict = {'cvec'     : 'Count Vectorizer',\n",
    "                      'tvec'     : 'TfidfVectorizer',\n",
    "                      'multi_nb' : 'MultinomialNB',\n",
    "                      'lr'       : 'Logistic Regression',\n",
    "                      'dt'       : 'Decision Tree Classifier',\n",
    "                      'rf'       : 'Random Forest Classifier',\n",
    "                      'ada'      : 'AdaBoost Classifier',\n",
    "                      'gb'       : 'Gradient Boosting Classifier',\n",
    "                      'xgb'      : 'XG Boost Classifier'\n",
    "                     }\n",
    "    \n",
    "    vec_dict =  {'cvec': CountVectorizer(),\n",
    "                 'tvec': TfidfVectorizer()\n",
    "                }\n",
    "    \n",
    "    param_dict = {'cvec': {'cvec__max_features': [2500, 3000, 3500],\n",
    "                           'cvec__min_df': [2, 3],\n",
    "                           'cvec__max_df': [.9, .95],\n",
    "                           'cvec__ngram_range': [(1,1), (1,2)]},\n",
    "                  'tvec': {'tvec__max_features': [2500, 3000, 3500],\n",
    "                           'tvec__min_df':[2,3],\n",
    "                           'tvec__max_df':[.9,.95],\n",
    "                           'tvec__ngram_range':[(1,1),(1,2)]},\n",
    "                  'dt' : {'dt__max_depth': [3,5],\n",
    "                          'dt__min_samples_split': [5,10],\n",
    "                          'dt__min_samples_leaf': [2,3]},\n",
    "                  'rf' : {'rf__n_estimators': [100],\n",
    "                          'rf__max_depth': [None, 1, 2],\n",
    "                          'rf__min_samples_split': [5,10],\n",
    "                          'rf__min_samples_leaf': [2,3]},\n",
    "                  'lr' : {},\n",
    "                  'multi_nb' : {},\n",
    "                  'ada': {'ada__n_estimators':[50,80],\n",
    "                          'ada__algorithm': ['SAMME', 'SAMME.R'],\n",
    "                          'ada__learning_rate': [0.9, 1.]\n",
    "                          },\n",
    "                  'gb': {'gb__max_depth': [2,3,4],\n",
    "                          'gb__n_estimators': [100, 125],\n",
    "                          'gb__learning_rate': [.08, .1]},\n",
    "                  'xgb': {}                    \n",
    "                  }\n",
    "\n",
    "    model_dict = {'multi_nb' : MultinomialNB(),\n",
    "                  'lr' : LogisticRegression(solver='lbfgs', max_iter = 1000),\n",
    "                  'dt' : DecisionTreeClassifier(),\n",
    "                  'rf' : RandomForestClassifier(),\n",
    "                  'ada': AdaBoostClassifier(),\n",
    "                  'gb' : GradientBoostingClassifier(),\n",
    "                  'xgb' : XGBClassifier()\n",
    "                  }\n",
    "    \n",
    "    pipe = Pipeline([(vectorizer, vec_dict[vectorizer]), \n",
    "                    ((model, model_dict[model]))])\n",
    "    \n",
    "    \n",
    "    param_dict[model].update(param_dict[vectorizer])\n",
    "    pipe_params = param_dict[model]\n",
    "    \n",
    "    grid = GridSearchCV(pipe,\n",
    "           param_grid=pipe_params,\n",
    "           cv=3)\n",
    "        \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'Using {full_name_dict[model]} Model and {full_name_dict[vectorizer]}:')\n",
    "    print(f'Model train score : {grid.best_score_}')\n",
    "    print(f'Model test score : {grid.score(X_test,y_test)}')\n",
    "    print(f'Model best params : {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression Model and Count Vectorizer:\n",
      "Model train score : 0.76445\n",
      "Model test score : 0.766675\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression Model and TfidfVectorizer:\n",
      "Model train score : 0.7647027777777777\n",
      "Model test score : 0.7670833333333333\n",
      "Model best params : {'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Decision Tree Classifier Model and Count Vectorizer:\n",
      "Model train score : 0.5213166666666667\n",
      "Model test score : 0.518825\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 2500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Decision Tree Classifier Model and TfidfVectorizer:\n",
      "Model train score : 0.521425\n",
      "Model test score : 0.5188\n",
      "Model best params : {'dt__max_depth': 5, 'dt__min_samples_leaf': 3, 'dt__min_samples_split': 5, 'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MultinomialNB Model and Count Vectorizer:\n",
      "Model train score : 0.7557583333333333\n",
      "Model test score : 0.7565\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3500, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','multi_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MultinomialNB Model and TfidfVectorizer:\n",
      "Model train score : 0.7556805555555556\n",
      "Model test score : 0.7560416666666666\n",
      "Model best params : {'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','multi_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using XG Boost Classifier Model and Count Vectorizer:\n",
      "Model train score : 0.6412527777777778\n",
      "Model test score : 0.6426333333333333\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using XG Boost Classifier Model and TfidfVectorizer:\n",
      "Model train score : 0.6438277777777778\n",
      "Model test score : 0.6442333333333333\n",
      "Model best params : {'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movie_reviews['final_review']\n",
    "y = movie_reviews['Freshness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression Model and Count Vectorizer:\n",
      "Model train score : 0.7682277777777777\n",
      "Model test score : 0.768275\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3500, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression Model and TfidfVectorizer:\n",
      "Model train score : 0.7683638888888888\n",
      "Model test score : 0.7683083333333334\n",
      "Model best params : {'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MultinomialNB Model and Count Vectorizer:\n",
      "Model train score : 0.7591638888888889\n",
      "Model test score : 0.7595333333333333\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3500, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','multi_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MultinomialNB Model and TfidfVectorizer:\n",
      "Model train score : 0.7586861111111111\n",
      "Model test score : 0.7586833333333334\n",
      "Model best params : {'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','multi_nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Decision Tree Classifier Model and Count Vectorizer:\n",
      "Model train score : 0.5292638888888889\n",
      "Model test score : 0.523125\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Decision Tree Classifier Model and TfidfVectorizer:\n",
      "Model train score : 0.5302055555555556\n",
      "Model test score : 0.5231333333333333\n",
      "Model best params : {'dt__max_depth': 5, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 5, 'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using XG Boost Classifier Model and Count Vectorizer:\n",
      "Model train score : 0.6508611111111111\n",
      "Model test score : 0.652775\n",
      "Model best params : {'cvec__max_df': 0.9, 'cvec__max_features': 3000, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'cvec','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using XG Boost Classifier Model and TfidfVectorizer:\n",
      "Model train score : 0.6519388888888888\n",
      "Model test score : 0.6531083333333333\n",
      "Model best params : {'tvec__max_df': 0.9, 'tvec__max_features': 3500, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "grid_searcher(X,y,'tvec','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
